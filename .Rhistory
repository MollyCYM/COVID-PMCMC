Z <- ((t_now) % 7 == 0 ? 0 : Z)
noise e
e ~ wiener()
ode(alg = 'RK4(3)', h = 1.0, atoler = 1.0e-3, rtoler = 1.0e-8) {
dx/dt = sigma*e
dS/dt = -exp(x)*S*I/N
dE/dt = exp(x)*S*I/N - E/k
dI/dt = E/k-I/gamma
dR/dt = I/gamma
dZ/dt = E/k
}
}
sub observation {
y ~ poisson(Z)
}
sub proposal_parameter {
k ~ gaussian(k, 0.005)
sigma ~ gaussian(sigma, 0.01)
gamma ~ gaussian(gamma, 0.01)
x0 ~ gaussian(x0, 0.05)
E0 ~ gaussian(E0, 0.05)
I0 ~ gaussian(I0, 0.05)
R0 ~ gaussian(R0, 0.05)
}
}"
model <- bi_model(lines = stringi::stri_split_lines(model_str)[[1]])
bi_model <- libbi(model)
input_lst <- list(N = 52196381)
end_time <- max(y$time)
obs_lst <- list(y = y %>% dplyr::filter(time <= end_time))
bi <- sample(bi_model, end_time = end_time, input = input_lst, obs = obs_lst, nsamples = 1000, nparticles = minParticles, nthreads = ncores, proposal = 'prior') %>%
adapt_particles(min = minParticles, max = minParticles*200) %>%
adapt_proposal(min = 0.05, max = 0.4) %>%
sample(nsamples = 5000, thin = 5) %>% # burn in
sample(nsamples = 5000, thin = 5)
bi_lst <- bi_read(bi %>% sample_obs)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(pander)
library(lubridate)
library(latex2exp)
knitr::opts_chunk$set(cache = T, echo = F, message = F, warning = F, dpi = 300)
theme_set(theme_bw())
# Appropiate colours for colourblind
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#999999")
scale_colour_discrete <- function(...)
scale_colour_manual(..., values = cbPalette)
scale_fill_discrete <- function(...)
scale_fill_manual(..., values = cbPalette)
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("andre_estimates_21_02.txt", sep  = "\t") %>%
rowSums()
y <- data.frame(value = v) %>%
mutate(time = seq(7, by = 7, length.out = n())) %>%
dplyr::select(time, value)
ncores <- 8
minParticles <- max(ncores, 16)
model_str <- "
model dureau {
obs y
state S
state E
state I
state R
state x
state Z
input N
param k
param gamma
param sigma // Noise driver
param E0
param I0
param R0
param x0
param tau
sub parameter {
k ~ truncated_gaussian(1.59, 0.02, lower = 0) // k is the period here, not the rate, i.e. 1/k is the rate
gamma ~ truncated_gaussian(1.08, 0.075, lower = 0) // gamma is the period, not the rate
sigma ~ uniform(0,1)
x0 ~ uniform(-5,2)
I0 ~ uniform(-16, -9)
E0 ~ uniform(-16, -9)
R0 ~ truncated_gaussian(0.15, 0.15, lower = 0, upper = 1)
tau ~ uniform(0, 1)
}
sub initial {
S <- N
R <- R0*S
S <- S - R
E <- exp(E0 + log(S))
S <- S - E
I <- exp(I0 + log(S))
S <- S - I
x <- x0
Z <- 0
}
sub transition(delta = 1) {
Z <- ((t_now) % 7 == 0 ? 0 : Z)
noise e
e ~ wiener()
ode(alg = 'RK4(3)', h = 1.0, atoler = 1.0e-3, rtoler = 1.0e-8) {
dx/dt = sigma*e
dS/dt = -exp(x)*S*I/N
dE/dt = exp(x)*S*I/N - E/k
dI/dt = E/k-I/gamma
dR/dt = I/gamma
dZ/dt = E/k
}
}
sub observation {
y ~ log_normal(log(max(Z/10.0, 0)), tau)
}
sub proposal_parameter {
k ~ gaussian(k, 0.005)
sigma ~ gaussian(sigma, 0.01)
gamma ~ gaussian(gamma, 0.01)
x0 ~ gaussian(x0, 0.05)
E0 ~ gaussian(E0, 0.05)
I0 ~ gaussian(I0, 0.05)
R0 ~ gaussian(R0, 0.05)
tau ~ gaussian(tau, 0.05)
}
}"
model <- bi_model(lines = stringi::stri_split_lines(model_str)[[1]])
bi_model <- libbi(model)
input_lst <- list(N = 52196381)
end_time <- max(y$time)
obs_lst <- list(y = y %>% dplyr::filter(time <= end_time))
bi <- sample(bi_model, end_time = end_time, input = input_lst, obs = obs_lst, nsamples = 1000, nparticles = minParticles, nthreads = ncores, proposal = 'prior') %>%
adapt_particles(min = minParticles, max = minParticles*200) %>%
adapt_proposal(min = 0.05, max = 0.4) %>%
sample(nsamples = 5000, thin = 5) %>% # burn in
sample(nsamples = 5000, thin = 5)
bi_lst <- bi_read(bi %>% sample_obs)
View(y)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(pander)
library(lubridate)
library(latex2exp)
knitr::opts_chunk$set(cache = T, echo = F, message = F, warning = F, dpi = 300)
theme_set(theme_bw())
# Appropiate colours for colourblind
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#999999")
scale_colour_discrete <- function(...)
scale_colour_manual(..., values = cbPalette)
scale_fill_discrete <- function(...)
scale_fill_manual(..., values = cbPalette)
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt", sep  = "\t") %>%
rowSums()
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt") %>%
rowSums()
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt", sep  = "\t") %>%
rowSums()
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt", header=FALSE, stringsAsFactors=FALSE,
fileEncoding="latin1") %>%
rowSums()
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt", header=FALSE, stringsAsFactors=FALSE,
fileEncoding="latin1") %>%
data.frame(value = v) %>%
rowSums()
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt", header=FALSE, stringsAsFactors=FALSE,
fileEncoding="latin1")
v<-data.frame(value = v) %>%
rowSums()
View(v)
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt", header=FALSE, stringsAsFactors=FALSE)
library(rbi)
library(rbi.helpers)
# Load the data
v <- read.csv("covid.txt", header=FALSE, stringsAsFactors=FALSE)
sigma ~ truncated_gaussian(0.20379467, 0.2, lower = 0)
gamma ~ truncated_gaussian(0.12460946, 0.2, lower = 0)
beta ~ truncated_gaussian(0.57586873, 0.3, lower = 0)
mu ~ truncated_gaussian(0.09454979, 0.001, lower = 0)
sigma <- rtruncnorm(20000, a=0, b=Inf, mean = 0.20379467, sd = 0.2)
library('truncnorm')
sigma <- rtruncnorm(20000, a=0, b=Inf, mean = 0.20379467, sd = 0.2)
write.csv(sigma,"sim_sigma.csv")
quantile(sigma,probs=0.975)
quantile(sigma,probs=0.025)
quantile(sigma,probs=0.5)
median(sigma)
plot(sigma,type='p')
abline(h=0.25, col="red")             #True
abline(h=0.2441596 ,col="pink")       #Median
abline(h=0.605125, col="pink", lty=2) #95% CI
abline(h=0.01798, col="pink", lty=2)  #95% CI
plot(sigma,type='p')
abline(h=0.25, col="red")             #True
abline(h=0.2441596 ,col="blue")       #Median
abline(h=0.605125, col="blue", lty=2) #95% CI
abline(h=0.01798, col="blue", lty=2)  #95% CI
gamma <- rtruncnorm(20000, a=0, b=Inf, mean = 0.12460946, sd = 0.2)
write.csv(gamma,"sim_gamma.csv")
quantile(gamma,probs=0.975)
quantile(gamma,probs=0.025)
quantile(gamma,probs=0.5)
plot(gamma,type='p')
abline(h=0.2, col="red")
abline(h=0.1918962 ,col="blue")
abline(h=0.540297, col="blue", lty=2)
abline(h=0.01032564, col="blue", lty=2)
beta <- rtruncnorm(20000, a=0, b=Inf, mean = 0.57586873, sd = 0.3)
write.csv(beta,"sim_beta.csv")
quantile(beta,probs=0.975)
quantile(beta,probs=0.025)
quantile(beta, probs = 0.5)
plot(beta,type='p')
abline(h=0.5, col="red")
abline(h=0.5878858 ,col="blue")
abline(h=1.166063 , col="blue", lty=2)
abline(h=0.08353307 , col="blue", lty=2)
mu <- rtruncnorm(20000, a=0, b=Inf, mean = 0.001, sd = 0.001)
write.csv(mu,"sim_mu1.csv")
quantile(mu,probs=0.975)
quantile(mu,probs=0.025)
quantile(mu, probs=0.5)
plot(mu,type='p')
abline(h=0.001, col="red")
abline(h=0.001187797 ,col="blue")
abline(h=0.003035988 , col="blue", lty=2)
abline(h=8.416168e-05, col="blue", lty=2)
library(hmer)
install.packages('hmer')
library(hmer)
library(deSolve)
library(ggplot2)
library(reshape2)
library(purrr)
library(tidyverse)
library(lhs)
set.seed(123)
ode_results <- function(parms, end_time = 365*2) {
forcer = matrix(c(0, parms['beta1'], 100, parms['beta2'], 180, parms['beta2'], 270, parms['beta3']),
ncol = 2, byrow = TRUE)
force_func = approxfun(x = forcer[,1], y = forcer[,2], method = "linear", rule = 2)
des = function(time, state, parms) {
with(as.list(c(state, parms)), {
dS <- b*(S+E+I+R)-force_func(time)*I*S/(S+E+I+R) + omega*R - mu*S
dE <- force_func(time)*I*S/(S+E+I+R) - epsilon*E - mu*E
dI <- epsilon*E - alpha*I - gamma*I - mu*I
dR <- gamma*I - omega*R - mu*R
return(list(c(dS, dE, dI, dR)))
})
}
yini = c(S = 900, E = 100, I = 0, R = 0)
times = seq(0, end_time, by = 1)
out = deSolve::ode(yini, times, des, parms)
return(out)
}
# `get_results` acts as `ode_results`, but has the additional feature
# of allowing us to decide which outputs and times should be returned.
# For example, to obtain the number of infected and susceptible individuals
# at t=25 and t=50, we would set `times=c(25,50)` and `outputs=c('I','S')`.
get_results <- function(params, times, outputs) {
t_max <- max(times)
all_res <- ode_results(params, t_max)
actual_res <- all_res[all_res[,'time'] %in% times, c('time', outputs)]
shaped <- reshape2::melt(actual_res[,outputs])
return(setNames(shaped$value, paste0(shaped$Var2, actual_res[,'time'], sep = "")))
}
example_params <- c(
b = 1/(60*365),
mu = 1/(76*365),
beta1 = 0.2, beta2 = 0.1, beta3 = 0.3,
epsilon = 0.13,
alpha = 0.01,
gamma = 0.08,
omega = 0.003
)
solution <- ode_results(example_params)
par(mar = c(2, 2, 2, 2))
plot(solution)
example_params <- c(
b = 1/(60*365),
mu = 1/(76*365),
beta1 = 0.2, beta2 = 0.1, beta3 = 0.3,
epsilon = 0.13,
alpha = 0.001,
gamma = 0.08,
omega = 0.003
)
solution <- ode_results(example_params)
par(mar = c(2, 2, 2, 2))
plot(solution)
example_params <- c(
b = 1/(60*365),
mu = 1/(76*365),
beta1 = 0.2, beta2 = 0.1, beta3 = 0.3,
epsilon = 0.13,
alpha = 0.001,
gamma = 0.1,
omega = 0.003
)
solution <- ode_results(example_params)
par(mar = c(2, 2, 2, 2))
plot(solution)
example_params <- c(
b = 1/(60*365),
mu = 1/(76*365),
beta1 = 0.2, beta2 = 0.1, beta3 = 0.3,
epsilon = 0.13,
alpha = 0.001,
gamma = 0.0001,
omega = 0.003
)
solution <- ode_results(example_params)
par(mar = c(2, 2, 2, 2))
plot(solution)
example_params <- c(
b = 1/(60*365),
mu = 1/(76*365),
beta1 = 0.2, beta2 = 0.1, beta3 = 0.3,
epsilon = 0.13,
alpha = 0.01,
gamma = 0.08,
omega = 0.003
)
solution <- ode_results(example_params)
par(mar = c(2, 2, 2, 2))
plot(solution)
# Define the parameter ranges
ranges = list(
b = c(1e-5, 1e-4), # birth rate
mu = c(1e-5, 1e-4), # rate of death from other causes
beta1 = c(0.2, 0.3), # infection rate from time t=0
beta2 = c(0.1, 0.2), # infection rate from time t=100
beta3 = c(0.3, 0.5), # infection rate from time t=270
epsilon = c(0.07, 0.21), # rate of becoming infectious after infection
alpha = c(0.01, 0.025), # rate of death from the disease
gamma = c(0.05, 0.08), # recovery rate
omega = c(0.002, 0.004) # rate at which immunity is lost following recovery
)
# Define the targets' mean values and standard deviations
targets <- list(
I25 = list(val = 115.88, sigma = 5.79),
I40 = list(val = 137.84, sigma = 6.89),
I100 = list(val = 26.34, sigma = 1.317),
I200 = list(val = 0.68, sigma = 0.034),
I300 = list(val = 29.55, sigma = 1.48),
I350 = list(val = 68.89, sigma = 3.44),
R25 = list(val = 125.12, sigma = 6.26),
R40 = list(val = 256.80, sigma = 12.84),
R100 = list(val = 538.99, sigma = 26.95),
R200 = list(val = 444.23, sigma = 22.21),
R300 = list(val = 371.08, sigma = 15.85),
R350 = list(val = 549.42, sigma = 27.47)
)
# The parameter set below was used to determine the targets. The model was run on it and the outputs taken to
# be the mean value of the targets. The standard deviations were defined as 5% of the corresponding mean value.
chosen_params <- list(b = 1/(76*365), mu = 1/(76*365), beta1 = 0.214,
beta2 = 0.107, beta3 = 0.428, epsilon = 1/7, alpha = 1/50, gamma = 1/14, omega = 1/365)
# Define two Latin hypercube designs through the function `maximinLHS`. This function assumes that each parameter
# is distributed on [0,1]
initial_LHS_training <- maximinLHS(90, 9)
initial_LHS_validation <- maximinLHS(90, 9)
initial_LHS <- rbind(initial_LHS_training, initial_LHS_validation)
# Rescale the parameter ranges from [0,1] to the correct ranges, and add columns names to identify the parameters
initial_points <- setNames(data.frame(t(apply(initial_LHS, 1,
function(x) x*unlist(lapply(ranges, function(x) x[2]-x[1])) +
unlist(lapply(ranges, function(x) x[1]))))), names(ranges))
# Run the model on `initial_points` and add column names to identify the different targets
initial_results <- setNames(data.frame(t(apply(initial_points, 1, get_results,
c(25, 40, 100, 200, 300, 350), c('I', 'R')))), names(targets))
# Bind `initial_points` and the corresponding model outputs `initial_results` by column
wave0 <- cbind(initial_points, initial_results)
wave0
write.csv(wave0,"wave0.csv")
training <- wave0[1:90,]
validation <- wave0[91:180,]
ems_wave1 <- emulator_from_data(training, names(targets), ranges,
c_lengths= rep(0.55,length(targets)))
ems_wave1$R200
emulator_plot(ems_wave1$R200, params = c('beta1', 'gamma'))
plot_actives(ems_wave1)
emulator_plot(ems_wave1$R200, plot_type = 'var', params = c('beta1', 'gamma'))
# Exami
emulator_plot(ems_wave1$R200, plot_type= 'exp', params = c('beta1', 'gamma'))
emulator_plot(ems_wave1$R200, plot_type= 'var', params = c('beta1', 'gamma'))
emulator_plot(ems_wave1$R200, params = c('beta2', 'gamma'))
emulator_plot(ems_wave1$R200, params = c('beta1', 'gamma'))
log(max((sigma*E)/5
,0
)
log(max((sigma*E)/5,0))
v <- read.csv("simulate366_2.csv", header=FALSE, stringsAsFactors=FALSE)
typeof(model_str)
model_str
rm(list=ls())
require(deSolve)
SEIR <- function(time, current_state, params){
with(as.list(c(current_state, params)),{
N <- S+E+I+R
dS <- -(beta*S*I)/N
dE <- (beta*S*I)/N - sigma*E
dI <- sigma*E - gamma*I - mu*I
dR <- gamma*I
dM <- mu*I
return(list(c(dS, dE, dI, dR, dM)))
})
}
params <- c(beta=0.5, sigma=0.25, gamma=0.2, mu=0.001)
initial_state <- c(S=999999, E=1, I=0, R=0, M=0)
times <- 0:365
model <- ode(initial_state, times, SEIR, params)
summary(model)
matplot(model, type="l", lty=1, main="SEIR model", xlab="Time")
legend <- colnames(model)[2:6]
legend("right", legend=legend, col=2:6, lty = 1)
write.csv(model,"simulatestates3.csv")
View(model)
Z <-0.2*model[,3]
write.csv(Z,"simZ3.csv")
tau <-0.8
Y <-vector(length = 366)
for (i in 1:366){
Y[i]<- rlnorm(1,log(Z[i]/5),tau)
}
plot(Y,type='l')
write.csv(Y,"simY3.csv")
tau <-0.8
Y <-vector(length = 3)
for (i in 1:3){
Y[i]<- rlnorm(1,log(Z[i]/5),tau)
}
plot(Y,type='l')
rm(list=ls())
require(deSolve)
SEIR <- function(time, current_state, params){
with(as.list(c(current_state, params)),{
N <- S+E+I+R
dS <- -(beta*S*I)/N
dE <- (beta*S*I)/N - sigma*E
dI <- sigma*E - gamma*I - mu*I
dR <- gamma*I+mu*I
return(list(c(dS, dE, dI, dR)))
})
}
params <- c(beta=0.5, sigma=0.25, gamma=0.2, mu=0.001)
initial_state <- c(S=999999, E=1, I=0, R=0)
times <- 0:365
model <- ode(initial_state, times, SEIR, params)
summary(model)
matplot(model, type="l", lty=1, main="SEIR model", xlab="Time")
legend <- colnames(model)[2:5]
legend("right", legend=legend, col=2:5, lty = 1)
write.csv(model,"simulatestates4.csv")
Z <-0.2*model[,3]
tau <- 0.8
Y <-vector(length = 366)
for (i in 1:366){
Y[i]<- rlnorm(1,log(Z[i]/5),tau)
}
plot(Y,type='l')
write.csv(Y,"simY4.csv")
Mmodel <- read.csv("simulatestates4.csv", header=TRUE, stringsAsFactors=FALSE)
View(Mmodel)
sigma <- rtruncnorm(20000, a=0, b=Inf, mean = 0.20379467, sd = 0.1)
quantile(sigma,probs=0.975)
quantile(sigma,probs=0.025)
quantile(sigma,probs=0.5)
plot(sigma,type='p')
abline(h=0.25, col="red")             #True
abline(h=0.2078025 ,col="blue")       #Median
abline(h=0.404596 , col="blue", lty=2) #95% CI
abline(h=0.03397732 , col="blue", lty=2)  #9
plot(sigma,type='p')
abline(h=0.25, col="red")             #True
abline(h=0.2078025 ,col="blue")       #Median
abline(h=0.404596 , col="blue", lty=2) #95% CI
abline(h=0.03397732 , col="blue", lty=2)  #9
library(fs)
library(purrr)
library(rlang)
library(whisker)
# Read in template script
template <- readLines("para_template.R") #prepare base file
getwd()
setwd("/Users/mollycui/Desktop/R script/Research 10-Epid PMCMC")
library(fs)
library(purrr)
library(rlang)
library(whisker)
# Read in template script
template <- readLines("para_template.R") #prepare base file
output <- whisker.render(template, template_variables) #output store file?
